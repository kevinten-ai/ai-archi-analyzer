# ä½¿ç”¨ç¤ºä¾‹

æœ¬æ–‡æ¡£æä¾›AI Architecture Analyzerçš„å®Œæ•´ä½¿ç”¨ç¤ºä¾‹ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

### 1. åŸºç¡€æ¶æ„åˆ†æ

```python
import asyncio
from src.core.pipeline import PipelineOrchestrator

async def basic_analysis():
    """åŸºç¡€æ¶æ„åˆ†æç¤ºä¾‹"""
    # åˆ›å»ºç®¡é“ç¼–æ’å™¨
    orchestrator = PipelineOrchestrator()

    # å®šä¹‰è¦åˆ†æçš„åº”ç”¨IDåˆ—è¡¨
    app_ids = [
        "user-service",
        "order-service",
        "payment-service",
        "inventory-service"
    ]

    # æ‰§è¡Œæ¶æ„åˆ†æ
    result = await orchestrator.analyze_architecture(
        app_ids=app_ids,
        report_format="markdown",
        enable_progress_tracking=True
    )

    if result.success:
        print(f"åˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜è‡³: {result.report_path}")
        print(f"å¤„ç†æ—¶é—´: {result.processing_time:.2f}ç§’")
        print(f"æ¶æ„ç±»å‹: {result.architecture_analysis.architecture_type}")
        print(f"è´¨é‡è¯„åˆ†: {result.architecture_analysis.quality_score}/10")
    else:
        print(f"åˆ†æå¤±è´¥: {result.error_message}")

# è¿è¡Œç¤ºä¾‹
asyncio.run(basic_analysis())
```

### 2. ä½¿ç”¨APIæ¥å£

```python
import requests
import time

def api_analysis_example():
    """APIè°ƒç”¨ç¤ºä¾‹"""
    base_url = "http://localhost:8000"

    # 1. æäº¤åˆ†æä»»åŠ¡
    response = requests.post(
        f"{base_url}/api/analyze",
        json={
            "app_ids": ["web-app", "api-gateway", "database", "cache"],
            "report_format": "markdown",
            "enable_progress_tracking": True
        }
    )

    if response.status_code != 200:
        print("æäº¤ä»»åŠ¡å¤±è´¥")
        return

    task_id = response.json()["task_id"]
    print(f"ä»»åŠ¡å·²æäº¤ï¼ŒID: {task_id}")

    # 2. è½®è¯¢ä»»åŠ¡çŠ¶æ€
    while True:
        status_response = requests.get(f"{base_url}/api/tasks/{task_id}/status")

        if status_response.status_code != 200:
            print("è·å–çŠ¶æ€å¤±è´¥")
            break

        status_data = status_response.json()
        progress = status_data["progress"] * 100

        print(f"è¿›åº¦: {progress:.1f}% - {status_data['message']}")

        if status_data["status"] in ["completed", "failed"]:
            break

        time.sleep(2)  # ç­‰å¾…2ç§’åå†æ¬¡æ£€æŸ¥

    # 3. è·å–åˆ†æç»“æœ
    result_response = requests.get(f"{base_url}/api/tasks/{task_id}/result")

    if result_response.status_code == 200:
        result = result_response.json()
        if result["success"]:
            print("åˆ†ææˆåŠŸï¼")
            print(f"åº”ç”¨æ•°é‡: {result['total_apps']}")
            print(f"è´¨é‡è¯„åˆ†: {result['quality_score']}")
        else:
            print(f"åˆ†æå¤±è´¥: {result['error_message']}")

# è¿è¡Œç¤ºä¾‹
api_analysis_example()
```

## ğŸ“Š é«˜çº§ç”¨æ³•ç¤ºä¾‹

### 1. æ‰¹é‡åˆ†æå¤§è§„æ¨¡ç³»ç»Ÿ

```python
import asyncio
from src.core.pipeline import PipelineOrchestrator

async def large_scale_analysis():
    """å¤§è§„æ¨¡ç³»ç»Ÿåˆ†æç¤ºä¾‹"""
    orchestrator = PipelineOrchestrator()

    # æ¨¡æ‹Ÿå¤§è§„æ¨¡ç³»ç»Ÿï¼ˆ100ä¸ªåº”ç”¨ï¼‰
    app_ids = [f"service-{i:03d}" for i in range(1, 101)]

    print(f"å¼€å§‹åˆ†æ {len(app_ids)} ä¸ªåº”ç”¨...")

    # æ‰§è¡Œåˆ†æ
    result = await orchestrator.analyze_architecture(
        app_ids=app_ids,
        report_format="json",  # ä½¿ç”¨JSONæ ¼å¼ä¾¿äºç¨‹åºå¤„ç†
        enable_progress_tracking=True
    )

    if result.success:
        print("å¤§è§„æ¨¡åˆ†æå®Œæˆï¼")
        print(f"æ€»åº”ç”¨æ•°: {len(result.apps_data)}")
        print(f"æ¶æ„è´¨é‡è¯„åˆ†: {result.architecture_analysis.quality_score}")

        # åˆ†ææŠ€æœ¯æ ˆåˆ†å¸ƒ
        tech_stats = analyze_tech_stack(result.apps_data)
        print("æŠ€æœ¯æ ˆç»Ÿè®¡:")
        for tech, count in tech_stats.items():
            print(f"  {tech}: {count} ä¸ªåº”ç”¨")

def analyze_tech_stack(apps_data):
    """åˆ†ææŠ€æœ¯æ ˆåˆ†å¸ƒ"""
    tech_stats = {}
    for app in apps_data:
        tech = app.language or "Unknown"
        tech_stats[tech] = tech_stats.get(tech, 0) + 1
    return tech_stats

asyncio.run(large_scale_analysis())
```

### 2. è‡ªå®šä¹‰åˆ†æé…ç½®

```python
import asyncio
from src.core.pipeline import PipelineOrchestrator
from src.config.settings import settings

async def custom_analysis():
    """è‡ªå®šä¹‰é…ç½®åˆ†æç¤ºä¾‹"""

    # ä¿®æ”¹é…ç½®ï¼ˆç¤ºä¾‹ï¼‰
    settings.processing.max_concurrent_apps = 5  # é™ä½å¹¶å‘åº¦
    settings.processing.batch_size = 3  # å‡å°æ‰¹å¤„ç†å¤§å°
    settings.llm.temperature = 0.3  # é™ä½åˆ›é€ æ€§ï¼Œæé«˜ç¡®å®šæ€§

    orchestrator = PipelineOrchestrator()

    app_ids = ["critical-service-1", "critical-service-2"]

    result = await orchestrator.analyze_architecture(
        app_ids=app_ids,
        report_format="markdown"
    )

    print(f"è‡ªå®šä¹‰é…ç½®åˆ†æå®Œæˆ: {result.success}")

asyncio.run(custom_analysis())
```

### 3. é”™è¯¯å¤„ç†å’Œé‡è¯•

```python
import asyncio
from src.core.pipeline import PipelineOrchestrator
from src.processors.error_handler import with_error_handling, ArchAnalyzerError

async def error_handling_example():
    """é”™è¯¯å¤„ç†ç¤ºä¾‹"""
    orchestrator = PipelineOrchestrator()

    @with_error_handling(context="analysis_example", rethrow=False, default_value=None)
    async def safe_analysis(app_ids):
        """å¸¦é”™è¯¯å¤„ç†çš„åˆ†æå‡½æ•°"""
        return await orchestrator.analyze_architecture(app_ids)

    # æµ‹è¯•ä¸åŒåœºæ™¯
    test_cases = [
        ["valid-app-1", "valid-app-2"],  # æ­£å¸¸æƒ…å†µ
        [],  # ç©ºåˆ—è¡¨
        ["nonexistent-app"] * 100,  # å¤§é‡ä¸å­˜åœ¨çš„åº”ç”¨
    ]

    for i, app_ids in enumerate(test_cases, 1):
        print(f"\n=== æµ‹è¯•ç”¨ä¾‹ {i} ===")
        print(f"åº”ç”¨ID: {app_ids[:3]}{'...' if len(app_ids) > 3 else ''}")

        result = await safe_analysis(app_ids)

        if result and result.success:
            print(f"âœ… æˆåŠŸ: {len(result.apps_data)} ä¸ªåº”ç”¨å·²åˆ†æ")
        else:
            print(f"âŒ å¤±è´¥: {result.error_message if result else 'æœªçŸ¥é”™è¯¯'}")

asyncio.run(error_handling_example())
```

## ğŸ§ª æµ‹è¯•ç¤ºä¾‹

### 1. å•å…ƒæµ‹è¯•

```python
import pytest
from unittest.mock import AsyncMock, patch
from src.core.pipeline import PipelineOrchestrator

class TestArchitectureAnalysis:
    """æ¶æ„åˆ†ææµ‹è¯•"""

    @pytest.fixture
    async def orchestrator(self):
        """æµ‹è¯•å¤¹å…·"""
        return PipelineOrchestrator()

    @pytest.mark.asyncio
    async def test_successful_analysis(self, orchestrator):
        """æµ‹è¯•æˆåŠŸåˆ†æåœºæ™¯"""
        app_ids = ["test-app-1", "test-app-2"]

        # Mock å¤–éƒ¨ä¾èµ–
        with patch.object(orchestrator.collector, 'collect_batch_info') as mock_collect:
            mock_collect.return_value = [
                AsyncMock(success=True, app_info=AsyncMock(app_id=app_id))
                for app_id in app_ids
            ]

            result = await orchestrator.analyze_architecture(app_ids)

            assert result.success is True
            assert len(result.apps_data) == 2

    @pytest.mark.asyncio
    async def test_partial_failure_analysis(self, orchestrator):
        """æµ‹è¯•éƒ¨åˆ†å¤±è´¥åœºæ™¯"""
        app_ids = ["good-app", "bad-app"]

        with patch.object(orchestrator.collector, 'collect_batch_info') as mock_collect:
            mock_collect.return_value = [
                AsyncMock(success=True, app_info=AsyncMock(app_id="good-app")),
                AsyncMock(success=False, app_info=None, error_message="é‡‡é›†å¤±è´¥")
            ]

            result = await orchestrator.analyze_architecture(app_ids)

            # åº”è¯¥æˆåŠŸï¼Œä½†åªåŒ…å«æˆåŠŸçš„åº”ç”¨
            assert result.success is True
            assert len(result.apps_data) == 1
            assert result.apps_data[0].app_id == "good-app"
```

### 2. æ€§èƒ½æµ‹è¯•

```python
import asyncio
import time
from src.core.pipeline import PipelineOrchestrator

async def performance_test():
    """æ€§èƒ½æµ‹è¯•ç¤ºä¾‹"""
    orchestrator = PipelineOrchestrator()

    # æµ‹è¯•ä¸åŒè§„æ¨¡çš„ç³»ç»Ÿ
    test_sizes = [10, 50, 100]

    for size in test_sizes:
        app_ids = [f"perf-app-{i}" for i in range(size)]

        start_time = time.time()
        result = await orchestrator.analyze_architecture(app_ids)
        end_time = time.time()

        duration = end_time - start_time

        print(f"è§„æ¨¡ {size}: {duration:.2f}ç§’, å¹³å‡ {duration/size:.3f}ç§’/åº”ç”¨")

asyncio.run(performance_test())
```

## ğŸ”§ é…ç½®ç¤ºä¾‹

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env æ–‡ä»¶
# LLM é…ç½®
ARCHI_LLM__PROVIDER=openai
ARCHI_LLM__API_KEY=sk-your-openai-api-key
ARCHI_LLM__MODEL=gpt-4
ARCHI_LLM__TEMPERATURE=0.1
ARCHI_LLM__MAX_TOKENS=4000

# MCP é…ç½®
ARCHI_MCP__ENABLED=true
ARCHI_MCP__ENDPOINT=http://mcp-server.company.com:8080
ARCHI_MCP__TIMEOUT=30

# å¤„ç†é…ç½®
ARCHI_PROCESSING__MAX_CONCURRENT_APPS=20
ARCHI_PROCESSING__BATCH_SIZE=10
ARCHI_PROCESSING__OUTPUT_DIR=./analysis_reports

# APIé…ç½®
ARCHI_API__HOST=0.0.0.0
ARCHI_API__PORT=8000
ARCHI_API__WORKERS=4

# æ—¥å¿—é…ç½®
ARCHI_LOGGING__LEVEL=INFO
ARCHI_LOGGING__FILE_PATH=./logs/archi_analyzer.log

# è°ƒè¯•æ¨¡å¼
ARCHI_DEBUG=false
```

### ç¨‹åºåŒ–é…ç½®

```python
from src.config.settings import settings

def configure_for_production():
    """ç”Ÿäº§ç¯å¢ƒé…ç½®"""
    # LLMé…ç½®
    settings.llm.provider = "openai"
    settings.llm.model = "gpt-4"
    settings.llm.temperature = 0.1

    # å¤„ç†é…ç½®
    settings.processing.max_concurrent_apps = 50
    settings.processing.batch_size = 20

    # APIé…ç½®
    settings.api.host = "0.0.0.0"
    settings.api.port = 80
    settings.api.workers = 8

    # ç¦ç”¨è°ƒè¯•
    settings.debug = False

def configure_for_development():
    """å¼€å‘ç¯å¢ƒé…ç½®"""
    settings.debug = True
    settings.api.reload = True
    settings.processing.max_concurrent_apps = 5
    settings.llm.model = "gpt-3.5-turbo"  # ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
```

## ğŸ“ˆ ç›‘æ§å’Œæ—¥å¿—ç¤ºä¾‹

### æ—¥å¿—è®°å½•

```python
import structlog
from src.config.settings import settings

def setup_structured_logging():
    """è®¾ç½®ç»“æ„åŒ–æ—¥å¿—"""
    if settings.logging.level == "DEBUG":
        structlog.configure(
            processors=[
                structlog.stdlib.filter_by_level,
                structlog.stdlib.add_logger_name,
                structlog.stdlib.add_log_level,
                structlog.stdlib.PositionalArgumentsFormatter(),
                structlog.processors.TimeStamper(fmt="iso"),
                structlog.processors.StackInfoRenderer(),
                structlog.processors.format_exc_info,
                structlog.processors.UnicodeDecoder(),
                structlog.processors.JSONRenderer()
            ],
            context_class=dict,
            logger_factory=structlog.stdlib.LoggerFactory(),
            wrapper_class=structlog.stdlib.BoundLogger,
            cache_logger_on_first_use=True,
        )

# ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—
logger = structlog.get_logger()

async def monitored_analysis():
    """å¸¦ç›‘æ§çš„åˆ†æå‡½æ•°"""
    with logger.new(task_id="example-task") as task_logger:
        task_logger.info("å¼€å§‹æ¶æ„åˆ†æ")

        try:
            # æ‰§è¡Œåˆ†æ...
            task_logger.info("åˆ†æå®Œæˆ", duration=123.45, app_count=10)
        except Exception as e:
            task_logger.error("åˆ†æå¤±è´¥", error=str(e))
            raise
```

è¿™äº›ç¤ºä¾‹å±•ç¤ºäº†AI Architecture Analyzerçš„ä¸»è¦åŠŸèƒ½å’Œä½¿ç”¨æ–¹å¼ã€‚ä½ å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´é…ç½®å’Œä»£ç ã€‚



