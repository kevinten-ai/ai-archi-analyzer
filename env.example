# AI Architecture Analyzer 配置文件示例
# 复制此文件为 .env 并填入实际配置

# ========== LLM 配置 ==========
# 支持的提供商: openai, anthropic, azure, local
ARCHI_LLM__PROVIDER=openai

# OpenAI 配置
ARCHI_LLM__API_KEY=your_openai_api_key_here
ARCHI_LLM__BASE_URL=https://api.openai.com/v1
ARCHI_LLM__MODEL=gpt-4

# Anthropic 配置 (如果使用anthropic)
# ARCHI_LLM__API_KEY=your_anthropic_api_key_here
# ARCHI_LLM__MODEL=claude-3-sonnet-20240229

# LLM 参数
ARCHI_LLM__TEMPERATURE=0.1
ARCHI_LLM__MAX_TOKENS=4000
ARCHI_LLM__TIMEOUT=60

# ========== MCP 配置 ==========
# 是否启用MCP客户端
ARCHI_MCP__ENABLED=true

# MCP服务端点 (根据实际MCP服务地址修改)
ARCHI_MCP__ENDPOINT=http://localhost:8080/api

# MCP请求配置
ARCHI_MCP__TIMEOUT=30
ARCHI_MCP__RETRY_ATTEMPTS=3
ARCHI_MCP__RETRY_DELAY=1.0

# ========== 处理配置 ==========
# 最大并发应用数
ARCHI_PROCESSING__MAX_CONCURRENT_APPS=10

# 批处理大小
ARCHI_PROCESSING__BATCH_SIZE=5

# 进度跟踪
ARCHI_PROCESSING__ENABLE_PROGRESS_TRACKING=true

# 输出目录
ARCHI_PROCESSING__OUTPUT_DIR=./output

# 缓存目录
ARCHI_PROCESSING__CACHE_DIR=./cache

# ========== API服务配置 ==========
# 服务主机
ARCHI_API__HOST=0.0.0.0

# 服务端口
ARCHI_API__PORT=8000

# 工作进程数
ARCHI_API__WORKERS=1

# 开发模式自动重载
ARCHI_API__RELOAD=false

# CORS允许的源 (多个用逗号分隔)
ARCHI_API__CORS_ORIGINS=*

# ========== 日志配置 ==========
# 日志级别: DEBUG, INFO, WARNING, ERROR, CRITICAL
ARCHI_LOGGING__LEVEL=INFO

# 日志格式
ARCHI_LOGGING__FORMAT=%(asctime)s | %(levelname)s | %(name)s | %(message)s

# 日志文件路径 (可选，不设置则输出到控制台)
# ARCHI_LOGGING__FILE_PATH=./logs/archi_analyzer.log

# 日志文件大小限制
ARCHI_LOGGING__MAX_FILE_SIZE=10 MB

# 日志保留时间
ARCHI_LOGGING__RETENTION=7 days

# ========== 环境配置 ==========
# 运行环境: development, testing, staging, production
ARCHI_ENVIRONMENT=development

# 调试模式
ARCHI_DEBUG=true



